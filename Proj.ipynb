{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Harrison Ressler\n",
    "\n",
    "#CAUTION: ONLY RUN SOME CELLS ONCE, ELSE IT WILL REDO THINGS BASED OFF OF PREVIOUS CHANGES ALREADY DONE\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>cab_type</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>destination</th>\n",
       "      <th>source</th>\n",
       "      <th>price</th>\n",
       "      <th>surge_multiplier</th>\n",
       "      <th>id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1544952607890</td>\n",
       "      <td>North Station</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>424553bb-7174-41ea-aeb4-fe06d4f4b9d7</td>\n",
       "      <td>lyft_line</td>\n",
       "      <td>Shared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.44</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543284023677</td>\n",
       "      <td>North Station</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4bd23055-6827-41c6-b23b-3c491f24e74d</td>\n",
       "      <td>lyft_premier</td>\n",
       "      <td>Lux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.44</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543366822198</td>\n",
       "      <td>North Station</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>981a3613-77af-4620-a42a-0c0866077d1e</td>\n",
       "      <td>lyft</td>\n",
       "      <td>Lyft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.44</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543553582749</td>\n",
       "      <td>North Station</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>c2d88af2-d278-4bfd-a8d0-29ca77cc5512</td>\n",
       "      <td>lyft_luxsuv</td>\n",
       "      <td>Lux Black XL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543463360223</td>\n",
       "      <td>North Station</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>e0126e1f-8ca9-4f2e-82b3-50505a09db9a</td>\n",
       "      <td>lyft_plus</td>\n",
       "      <td>Lyft XL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance cab_type     time_stamp    destination            source  price  \\\n",
       "0      0.44     Lyft  1544952607890  North Station  Haymarket Square    5.0   \n",
       "1      0.44     Lyft  1543284023677  North Station  Haymarket Square   11.0   \n",
       "2      0.44     Lyft  1543366822198  North Station  Haymarket Square    7.0   \n",
       "3      0.44     Lyft  1543553582749  North Station  Haymarket Square   26.0   \n",
       "4      0.44     Lyft  1543463360223  North Station  Haymarket Square    9.0   \n",
       "\n",
       "   surge_multiplier                                    id    product_id  \\\n",
       "0               1.0  424553bb-7174-41ea-aeb4-fe06d4f4b9d7     lyft_line   \n",
       "1               1.0  4bd23055-6827-41c6-b23b-3c491f24e74d  lyft_premier   \n",
       "2               1.0  981a3613-77af-4620-a42a-0c0866077d1e          lyft   \n",
       "3               1.0  c2d88af2-d278-4bfd-a8d0-29ca77cc5512   lyft_luxsuv   \n",
       "4               1.0  e0126e1f-8ca9-4f2e-82b3-50505a09db9a     lyft_plus   \n",
       "\n",
       "           name  \n",
       "0        Shared  \n",
       "1           Lux  \n",
       "2          Lyft  \n",
       "3  Lux Black XL  \n",
       "4       Lyft XL  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\harri\\\\Desktop\\\\Cab_Project\\\\archive\\\\cab_rides.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 693071 entries, 0 to 693070\n",
      "Data columns (total 10 columns):\n",
      "distance            693071 non-null float64\n",
      "cab_type            693071 non-null object\n",
      "time_stamp          693071 non-null int64\n",
      "destination         693071 non-null object\n",
      "source              693071 non-null object\n",
      "price               637976 non-null float64\n",
      "surge_multiplier    693071 non-null float64\n",
      "id                  693071 non-null object\n",
      "product_id          693071 non-null object\n",
      "name                693071 non-null object\n",
      "dtypes: float64(3), int64(1), object(6)\n",
      "memory usage: 52.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data = df.copy() #Copying so I edit copy here and not core data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Clean Data\n",
    "#Step 1: Remove blank spaces or nulls, and things I won't need.\n",
    "\n",
    "#Drop id\n",
    "data = data.drop(columns = \"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Null rows : So, if any row has a null or NA it drops the ENTIRE row\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 637976 entries, 0 to 693070\n",
      "Data columns (total 9 columns):\n",
      "distance            637976 non-null float64\n",
      "cab_type            637976 non-null object\n",
      "time_stamp          637976 non-null int64\n",
      "destination         637976 non-null object\n",
      "source              637976 non-null object\n",
      "price               637976 non-null float64\n",
      "surge_multiplier    637976 non-null float64\n",
      "product_id          637976 non-null object\n",
      "name                637976 non-null object\n",
      "dtypes: float64(3), int64(1), object(5)\n",
      "memory usage: 48.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info() #Seeing how many rows dropped.\n",
    "#Previous: 693,071\n",
    "#Current: 637,976"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>price</th>\n",
       "      <th>surge_multiplier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>637976.000000</td>\n",
       "      <td>6.379760e+05</td>\n",
       "      <td>637976.000000</td>\n",
       "      <td>637976.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>2.189261</td>\n",
       "      <td>1.544046e+12</td>\n",
       "      <td>16.545125</td>\n",
       "      <td>1.015068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.135413</td>\n",
       "      <td>6.892028e+08</td>\n",
       "      <td>9.324359</td>\n",
       "      <td>0.095422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.543204e+12</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>1.543444e+12</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>2.160000</td>\n",
       "      <td>1.543737e+12</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>2.930000</td>\n",
       "      <td>1.544828e+12</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>7.860000</td>\n",
       "      <td>1.545161e+12</td>\n",
       "      <td>97.500000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            distance    time_stamp          price  surge_multiplier\n",
       "count  637976.000000  6.379760e+05  637976.000000     637976.000000\n",
       "mean        2.189261  1.544046e+12      16.545125          1.015068\n",
       "std         1.135413  6.892028e+08       9.324359          0.095422\n",
       "min         0.020000  1.543204e+12       2.500000          1.000000\n",
       "25%         1.270000  1.543444e+12       9.000000          1.000000\n",
       "50%         2.160000  1.543737e+12      13.500000          1.000000\n",
       "75%         2.930000  1.544828e+12      22.500000          1.000000\n",
       "max         7.860000  1.545161e+12      97.500000          3.000000"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 2: Grab Columns and clean up\n",
    "\n",
    "data.describe()\n",
    "#distance has a min of 0.02, max of 7.86 miles (presumably miles)\n",
    "#surge_multiplier has a max of 3.0. Mean is 1.013, so presumably it doesn't happen much. Meaning its very constant, so it might not be a good variable.\n",
    "#price generally from $7 to $25 (mean - std_dev = $7, mean + std_dev = $25)\n",
    "#time_stamp ... I'll need ot convert this into something else. So, currently its useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>price</th>\n",
       "      <th>surge_multiplier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>distance</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003290</td>\n",
       "      <td>0.345061</td>\n",
       "      <td>0.025946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>time_stamp</td>\n",
       "      <td>0.003290</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.000611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>price</td>\n",
       "      <td>0.345061</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.240458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>surge_multiplier</td>\n",
       "      <td>0.025946</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.240458</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  distance  time_stamp     price  surge_multiplier\n",
       "distance          1.000000    0.003290  0.345061          0.025946\n",
       "time_stamp        0.003290    1.000000  0.000808          0.000611\n",
       "price             0.345061    0.000808  1.000000          0.240458\n",
       "surge_multiplier  0.025946    0.000611  0.240458          1.000000"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert Columns from info above into something useful\n",
    "\n",
    "#I should probably make a correlation matrix here.\n",
    "\n",
    "data.corr()\n",
    "#Distance, price, & surge_multiplier seem fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   distance cab_type     time_stamp              destination  \\\n",
      "0      0.44     Lyft  1544952607890            North Station   \n",
      "1      0.44     Lyft  1543284023677            North Station   \n",
      "2      0.44     Lyft  1543366822198            North Station   \n",
      "3      0.44     Lyft  1543553582749            North Station   \n",
      "4      0.44     Lyft  1543463360223            North Station   \n",
      "5      0.44     Lyft  1545071112138            North Station   \n",
      "6      1.08     Lyft  1543208580200  Northeastern University   \n",
      "7      1.08     Lyft  1543780384677  Northeastern University   \n",
      "8      1.08     Lyft  1543818482645  Northeastern University   \n",
      "9      1.08     Lyft  1543315522249  Northeastern University   \n",
      "\n",
      "             source  price  surge_multiplier  product_id          name  \n",
      "0  Haymarket Square    5.0               1.0           0        Shared  \n",
      "1  Haymarket Square   11.0               1.0           1           Lux  \n",
      "2  Haymarket Square    7.0               1.0           2          Lyft  \n",
      "3  Haymarket Square   26.0               1.0           3  Lux Black XL  \n",
      "4  Haymarket Square    9.0               1.0           4       Lyft XL  \n",
      "5  Haymarket Square   16.5               1.0           5     Lux Black  \n",
      "6          Back Bay   10.5               1.0           4       Lyft XL  \n",
      "7          Back Bay   16.5               1.0           5     Lux Black  \n",
      "8          Back Bay    3.0               1.0           0        Shared  \n",
      "9          Back Bay   27.5               1.0           3  Lux Black XL  \n"
     ]
    }
   ],
   "source": [
    "#Now encode categorical (non-numeric) data\n",
    "\n",
    "len(data.product_id.factorize()[0]) # [0] shows first array instead of index, & len() shows its length\n",
    "data[\"product_id\"], product_id_labels = data.product_id.factorize() #Converting strings, into numbers that I can use (Ex: lyft_line -> 0, lyft_priemer -> 1, etc.)\n",
    "#product_id_labels allows me to link back to what the string is. \n",
    "#GOOGLE HOW TO DO ABOVE: \"GOOGLE: REVERSE PANDAS FACTORIZE\"\n",
    "print(data[:10])\n",
    "#Shows that I put product_id it puts into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['lyft_line', 'lyft_premier', 'lyft', 'lyft_luxsuv', 'lyft_plus',\n",
      "       'lyft_lux', '6f72dfc5-27f1-42e8-84db-ccc7a75f6969',\n",
      "       '6c84fd89-3f11-4782-9b50-97c468b19529',\n",
      "       '55c66225-fbe7-4fd5-9072-eab1ece5e23e',\n",
      "       '9a0e7b09-b92b-4c41-9779-2ad22b4d779d',\n",
      "       '6d318bcc-22a3-4af6-bddd-b409bfce1546',\n",
      "       '997acbb5-e102-41e1-b155-9df7de0a73f2'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(product_id_labels) #Why are there numbers?\n",
    "#Should see the number ones are a significant percent of the data, els, filter out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9a0e7b09-b92b-4c41-9779-2ad22b4d779d    55096\n",
       "6f72dfc5-27f1-42e8-84db-ccc7a75f6969    55096\n",
       "6d318bcc-22a3-4af6-bddd-b409bfce1546    55096\n",
       "6c84fd89-3f11-4782-9b50-97c468b19529    55095\n",
       "8cf7e821-f0d3-49c6-8eba-e679c0ebcf6a    55095\n",
       "55c66225-fbe7-4fd5-9072-eab1ece5e23e    55094\n",
       "997acbb5-e102-41e1-b155-9df7de0a73f2    55091\n",
       "lyft_premier                            51235\n",
       "lyft_lux                                51235\n",
       "lyft_luxsuv                             51235\n",
       "lyft                                    51235\n",
       "lyft_plus                               51235\n",
       "lyft_line                               51233\n",
       "Name: product_id, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shows how much of each each value (Ex: lyft-line) there is.\n",
    "df['product_id'].value_counts()\n",
    "#Wow. There is 55096 of stuff that I don't know what it is. That is a significant protion of the data.\n",
    "#I'm guessing the people who put the data togtehr did it intentionally.\n",
    "#But what is it? Random taxi cab companies?\n",
    "\n",
    "#LOOK AT THE SITE YOU GOT IT FROM LATER (KAGGLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   distance cab_type     time_stamp              destination  \\\n",
      "0      0.44     Lyft  1544952607890            North Station   \n",
      "1      0.44     Lyft  1543284023677            North Station   \n",
      "2      0.44     Lyft  1543366822198            North Station   \n",
      "3      0.44     Lyft  1543553582749            North Station   \n",
      "4      0.44     Lyft  1543463360223            North Station   \n",
      "5      0.44     Lyft  1545071112138            North Station   \n",
      "6      1.08     Lyft  1543208580200  Northeastern University   \n",
      "7      1.08     Lyft  1543780384677  Northeastern University   \n",
      "8      1.08     Lyft  1543818482645  Northeastern University   \n",
      "9      1.08     Lyft  1543315522249  Northeastern University   \n",
      "\n",
      "             source  price  surge_multiplier  product_id          name  \n",
      "0  Haymarket Square    5.0               1.0           0        Shared  \n",
      "1  Haymarket Square   11.0               1.0           1           Lux  \n",
      "2  Haymarket Square    7.0               1.0           2          Lyft  \n",
      "3  Haymarket Square   26.0               1.0           3  Lux Black XL  \n",
      "4  Haymarket Square    9.0               1.0           4       Lyft XL  \n",
      "5  Haymarket Square   16.5               1.0           5     Lux Black  \n",
      "6          Back Bay   10.5               1.0           4       Lyft XL  \n",
      "7          Back Bay   16.5               1.0           5     Lux Black  \n",
      "8          Back Bay    3.0               1.0           0        Shared  \n",
      "9          Back Bay   27.5               1.0           3  Lux Black XL  \n"
     ]
    }
   ],
   "source": [
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do same as above for factorizeing data with other non-numerical data (cab_type & name)\n",
    "data[\"cab_type\"], cab_type_labels = data.cab_type.factorize() #Converting strings, into numbers that I can use (Ex: Lyft -> 0, uber -> 1, etc.)\n",
    "#cab_type_labels allows me to link back to what the string is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"name\"], name_labels = data.name.factorize() #Converting strings, into numbers that I can use (Ex: shared -> 0, Lux -> 1, etc.)\n",
    "#name_labels allows me to link back to what the string is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   distance  cab_type     time_stamp              destination  \\\n",
      "0      0.44         0  1544952607890            North Station   \n",
      "1      0.44         0  1543284023677            North Station   \n",
      "2      0.44         0  1543366822198            North Station   \n",
      "3      0.44         0  1543553582749            North Station   \n",
      "4      0.44         0  1543463360223            North Station   \n",
      "5      0.44         0  1545071112138            North Station   \n",
      "6      1.08         0  1543208580200  Northeastern University   \n",
      "7      1.08         0  1543780384677  Northeastern University   \n",
      "8      1.08         0  1543818482645  Northeastern University   \n",
      "9      1.08         0  1543315522249  Northeastern University   \n",
      "\n",
      "             source  price  surge_multiplier  product_id  name  \n",
      "0  Haymarket Square    5.0               1.0           0     0  \n",
      "1  Haymarket Square   11.0               1.0           1     1  \n",
      "2  Haymarket Square    7.0               1.0           2     2  \n",
      "3  Haymarket Square   26.0               1.0           3     3  \n",
      "4  Haymarket Square    9.0               1.0           4     4  \n",
      "5  Haymarket Square   16.5               1.0           5     5  \n",
      "6          Back Bay   10.5               1.0           4     4  \n",
      "7          Back Bay   16.5               1.0           5     5  \n",
      "8          Back Bay    3.0               1.0           0     0  \n",
      "9          Back Bay   27.5               1.0           3     3  \n"
     ]
    }
   ],
   "source": [
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   distance cab_type     time_stamp              destination  \\\n",
      "0      0.44     Lyft  1544952607890            North Station   \n",
      "1      0.44     Lyft  1543284023677            North Station   \n",
      "2      0.44     Lyft  1543366822198            North Station   \n",
      "3      0.44     Lyft  1543553582749            North Station   \n",
      "4      0.44     Lyft  1543463360223            North Station   \n",
      "5      0.44     Lyft  1545071112138            North Station   \n",
      "6      1.08     Lyft  1543208580200  Northeastern University   \n",
      "7      1.08     Lyft  1543780384677  Northeastern University   \n",
      "8      1.08     Lyft  1543818482645  Northeastern University   \n",
      "9      1.08     Lyft  1543315522249  Northeastern University   \n",
      "\n",
      "             source  price  surge_multiplier  \\\n",
      "0  Haymarket Square    5.0               1.0   \n",
      "1  Haymarket Square   11.0               1.0   \n",
      "2  Haymarket Square    7.0               1.0   \n",
      "3  Haymarket Square   26.0               1.0   \n",
      "4  Haymarket Square    9.0               1.0   \n",
      "5  Haymarket Square   16.5               1.0   \n",
      "6          Back Bay   10.5               1.0   \n",
      "7          Back Bay   16.5               1.0   \n",
      "8          Back Bay    3.0               1.0   \n",
      "9          Back Bay   27.5               1.0   \n",
      "\n",
      "                                     id    product_id          name  \n",
      "0  424553bb-7174-41ea-aeb4-fe06d4f4b9d7     lyft_line        Shared  \n",
      "1  4bd23055-6827-41c6-b23b-3c491f24e74d  lyft_premier           Lux  \n",
      "2  981a3613-77af-4620-a42a-0c0866077d1e          lyft          Lyft  \n",
      "3  c2d88af2-d278-4bfd-a8d0-29ca77cc5512   lyft_luxsuv  Lux Black XL  \n",
      "4  e0126e1f-8ca9-4f2e-82b3-50505a09db9a     lyft_plus       Lyft XL  \n",
      "5  f6f6d7e4-3e18-4922-a5f5-181cdd3fa6f2      lyft_lux     Lux Black  \n",
      "6  462816a3-820d-408b-8549-0b39e82f65ac     lyft_plus       Lyft XL  \n",
      "7  474d6376-bc59-4ec9-bf57-4e6d6faeb165      lyft_lux     Lux Black  \n",
      "8  4f9fee41-fde3-4767-bbf1-a00e108701fb     lyft_line        Shared  \n",
      "9  8612d909-98b8-4454-a093-30bd48de0cb3   lyft_luxsuv  Lux Black XL  \n"
     ]
    }
   ],
   "source": [
    "print(df[:10]) #Showing original data un-cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         Haymarket Square\n",
      "1         Haymarket Square\n",
      "2         Haymarket Square\n",
      "3         Haymarket Square\n",
      "4         Haymarket Square\n",
      "                ...       \n",
      "693065           North End\n",
      "693066           North End\n",
      "693067           North End\n",
      "693069           North End\n",
      "693070           North End\n",
      "Length: 1275952, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#source & destination are unique because both should be lined up numerically with each other\n",
    "# because a person might be going from place A to B. Or vice vers (B to A)\n",
    "\n",
    "#concatonate to a pandas columns\n",
    "\n",
    "c = pd.concat([data.source, data.destination])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 2 2 2] Index(['Haymarket Square', 'Back Bay', 'North End', 'North Station',\n",
      "       'Beacon Hill', 'Boston University', 'Fenway', 'South Station',\n",
      "       'Theatre District', 'West End', 'Financial District',\n",
      "       'Northeastern University'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Now factorize it like others\n",
    "c_fact , c_labels = c.factorize() #Converting strings, into numbers that I can use (Ex: Haymarket Square -> 0, Back Bay -> 1, etc.)\n",
    "print(c_fact, c_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now split it up, and put back into df coulmns(source & destination)\n",
    "c_half1 = c_fact[:len(c_fact)//2] #Grabs all of the stuff from begging to halfway through. \"//2\" divides by 2 & returns an interger since it rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637976\n"
     ]
    }
   ],
   "source": [
    "print(len(c_half1)) #63k is the first half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_half2 = c_fact[len(c_fact)//2:] #Grabs all of the stuff from 2nd half. \"//2\" divides by 2 & returns an interger since it rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637976\n"
     ]
    }
   ],
   "source": [
    "print(len(c_half2))\n",
    "#Matches length of c_half1, so its good, & we aren't missing any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"source\"] = c_half1 #Since c_half1 is source\n",
    "data[\"destination\"] = c_half2 #Since c_half2 is destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        distance  cab_type     time_stamp  destination  source  price  \\\n",
      "0           0.44         0  1544952607890            3       0    5.0   \n",
      "1           0.44         0  1543284023677            3       0   11.0   \n",
      "2           0.44         0  1543366822198            3       0    7.0   \n",
      "3           0.44         0  1543553582749            3       0   26.0   \n",
      "4           0.44         0  1543463360223            3       0    9.0   \n",
      "...          ...       ...            ...          ...     ...    ...   \n",
      "693065      1.00         1  1543708385534            2       9    9.5   \n",
      "693066      1.00         1  1543708385534            2       9   13.0   \n",
      "693067      1.00         1  1543708385534            2       9    9.5   \n",
      "693069      1.00         1  1543708385534            2       9   27.0   \n",
      "693070      1.00         1  1543708385534            2       9   10.0   \n",
      "\n",
      "        surge_multiplier  product_id  name  \n",
      "0                    1.0           0     0  \n",
      "1                    1.0           1     1  \n",
      "2                    1.0           2     2  \n",
      "3                    1.0           3     3  \n",
      "4                    1.0           4     4  \n",
      "...                  ...         ...   ...  \n",
      "693065               1.0           9     9  \n",
      "693066               1.0           6     6  \n",
      "693067               1.0           8     8  \n",
      "693069               1.0          10    10  \n",
      "693070               1.0          11    11  \n",
      "\n",
      "[637976 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data) #Checking it worked. Yes, it matches the numers given above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we should fix time_stamp\n",
    "\n",
    "#Converts time after 1970:\n",
    "data[\"time_stamp\"] = pd.to_datetime(data.time_stamp, unit = \"ms\")\n",
    "#Since data has 13 numbers, unit is \"Millseconds\", default for paramter is seconds, when tried default said first day was 1970, uber not in 1970\n",
    "#It says it starts in 2018. That sounds probably correct\n",
    "#data = ... saves it to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        distance  cab_type              time_stamp  destination  source  \\\n",
      "0           0.44         0 2018-12-16 09:30:07.890            3       0   \n",
      "1           0.44         0 2018-11-27 02:00:23.677            3       0   \n",
      "2           0.44         0 2018-11-28 01:00:22.198            3       0   \n",
      "3           0.44         0 2018-11-30 04:53:02.749            3       0   \n",
      "4           0.44         0 2018-11-29 03:49:20.223            3       0   \n",
      "...          ...       ...                     ...          ...     ...   \n",
      "693065      1.00         1 2018-12-01 23:53:05.534            2       9   \n",
      "693066      1.00         1 2018-12-01 23:53:05.534            2       9   \n",
      "693067      1.00         1 2018-12-01 23:53:05.534            2       9   \n",
      "693069      1.00         1 2018-12-01 23:53:05.534            2       9   \n",
      "693070      1.00         1 2018-12-01 23:53:05.534            2       9   \n",
      "\n",
      "        price  surge_multiplier  product_id  name  \n",
      "0         5.0               1.0           0     0  \n",
      "1        11.0               1.0           1     1  \n",
      "2         7.0               1.0           2     2  \n",
      "3        26.0               1.0           3     3  \n",
      "4         9.0               1.0           4     4  \n",
      "...       ...               ...         ...   ...  \n",
      "693065    9.5               1.0           9     9  \n",
      "693066   13.0               1.0           6     6  \n",
      "693067    9.5               1.0           8     8  \n",
      "693069   27.0               1.0          10    10  \n",
      "693070   10.0               1.0          11    11  \n",
      "\n",
      "[637976 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data) #Checking if time_stamp useable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will get the numbers (Ex: Year, Day, Hour etc) that is likely useful in predicting pay\n",
    "#Google: \"Pandas Hours from datetime\" -> once we find out how to do one (Ex: Hour, or day, or year) we can do the other.\n",
    "\n",
    "data[\"minute\"] = data.time_stamp.dt.minute\n",
    "data[\"hour\"] = data.time_stamp.dt.hour #making new column \"hour\". dt = datetime\n",
    "data[\"day\"] = data.time_stamp.dt.day\n",
    "data[\"month\"] = data.time_stamp.dt.month\n",
    "data[\"year\"] = data.time_stamp.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        distance  cab_type              time_stamp  destination  source  \\\n",
      "0           0.44         0 2018-12-16 09:30:07.890            3       0   \n",
      "1           0.44         0 2018-11-27 02:00:23.677            3       0   \n",
      "2           0.44         0 2018-11-28 01:00:22.198            3       0   \n",
      "3           0.44         0 2018-11-30 04:53:02.749            3       0   \n",
      "4           0.44         0 2018-11-29 03:49:20.223            3       0   \n",
      "...          ...       ...                     ...          ...     ...   \n",
      "693065      1.00         1 2018-12-01 23:53:05.534            2       9   \n",
      "693066      1.00         1 2018-12-01 23:53:05.534            2       9   \n",
      "693067      1.00         1 2018-12-01 23:53:05.534            2       9   \n",
      "693069      1.00         1 2018-12-01 23:53:05.534            2       9   \n",
      "693070      1.00         1 2018-12-01 23:53:05.534            2       9   \n",
      "\n",
      "        price  surge_multiplier  product_id  name  minute  hour  day  month  \\\n",
      "0         5.0               1.0           0     0      30     9   16     12   \n",
      "1        11.0               1.0           1     1       0     2   27     11   \n",
      "2         7.0               1.0           2     2       0     1   28     11   \n",
      "3        26.0               1.0           3     3      53     4   30     11   \n",
      "4         9.0               1.0           4     4      49     3   29     11   \n",
      "...       ...               ...         ...   ...     ...   ...  ...    ...   \n",
      "693065    9.5               1.0           9     9      53    23    1     12   \n",
      "693066   13.0               1.0           6     6      53    23    1     12   \n",
      "693067    9.5               1.0           8     8      53    23    1     12   \n",
      "693069   27.0               1.0          10    10      53    23    1     12   \n",
      "693070   10.0               1.0          11    11      53    23    1     12   \n",
      "\n",
      "        year  \n",
      "0       2018  \n",
      "1       2018  \n",
      "2       2018  \n",
      "3       2018  \n",
      "4       2018  \n",
      "...      ...  \n",
      "693065  2018  \n",
      "693066  2018  \n",
      "693067  2018  \n",
      "693069  2018  \n",
      "693070  2018  \n",
      "\n",
      "[637976 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data) #Checking that numbers match (Ex: time_stamp : 2018 ..., year: 2018) and do for all new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It looks like all the data is now numeric, useable, and clean.\n",
    "\n",
    "##Phase 2: Now lets begin working on Model Selection\n",
    "\n",
    "#So, to use the models, we need to split the data up into training data, & testing data.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=1) \n",
    "#test_size is % of data used for testing, random_state is used for testing where it allows a random genrator to create data from the number given -\n",
    "#(Ex: If 1, then numbers will be generated around 1, can set consistancy by choosing where it randomly gerneates around (in this case 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainSet:\n",
      " distance            510380\n",
      "cab_type            510380\n",
      "time_stamp          510380\n",
      "destination         510380\n",
      "source              510380\n",
      "price               510380\n",
      "surge_multiplier    510380\n",
      "product_id          510380\n",
      "name                510380\n",
      "minute              510380\n",
      "hour                510380\n",
      "day                 510380\n",
      "month               510380\n",
      "year                510380\n",
      "dtype: int64\n",
      "\n",
      "TestSet:\n",
      " distance            127596\n",
      "cab_type            127596\n",
      "time_stamp          127596\n",
      "destination         127596\n",
      "source              127596\n",
      "price               127596\n",
      "surge_multiplier    127596\n",
      "product_id          127596\n",
      "name                127596\n",
      "minute              127596\n",
      "hour                127596\n",
      "day                 127596\n",
      "month               127596\n",
      "year                127596\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"TrainSet:\\n\", train_set.count()) #Can see that it is 80% of the data\n",
    "print(\"\\nTestSet:\\n\", test_set.count()) #Can see that it is 20% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that its split, we can start trying various models.\n",
    "\n",
    "#Separate Predictors (X variables) and target/outcome (y variable)\n",
    "dropped_variables = [\"price\", \"time_stamp\", \"destination\"] #List of variables that will not be used as X variables\n",
    "\n",
    "#Training will be used to train the data(80% of data). Test will be used ot compare the data to TEST if its correct (20% of the data)\n",
    "X_train = train_set.drop(dropped_variables, axis=1) #X variables are trying to predict Y. Don't give it Y. (Y is price) And time_stamp would not be helpful (But Hour, month etc would), so drop\n",
    "y_train = train_set[\"price\"].copy() #price is the y variable\n",
    "X_test = test_set.drop(dropped_variables, axis=1)\n",
    "y_test = test_set[\"price\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 510380 entries, 613406 to 139061\n",
      "Data columns (total 11 columns):\n",
      "distance            510380 non-null float64\n",
      "cab_type            510380 non-null int64\n",
      "source              510380 non-null int64\n",
      "surge_multiplier    510380 non-null float64\n",
      "product_id          510380 non-null int64\n",
      "name                510380 non-null int64\n",
      "minute              510380 non-null int64\n",
      "hour                510380 non-null int64\n",
      "day                 510380 non-null int64\n",
      "month               510380 non-null int64\n",
      "year                510380 non-null int64\n",
      "dtypes: float64(2), int64(9)\n",
      "memory usage: 46.7 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info() #Data looks ok. Nothings there that shouldn't be there.\n",
    "#So, its probably true for other newly created stuff from above (y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\"Visualize the data to gain insights\"\n",
    "#Month to anything\n",
    "#Determine pay per hour - ASK NAJAFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\"LOOK FOR CORRELATIONS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "####THINK ABOUT EXPERIMENT WITH ATTRIBUTE COMBINATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\"Separate the Predictors and the Labels\" if models need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE TO SELF: CURRENTLY I AM JUST TRYING AS MANY THINGS AS I CAN AND HIOPING ONE STICKS.\n",
    "#I DON'T THINK THATS A GOOD SYSTEM. FIND A DEDICATED PROCESS TO DETERRMINE WHICH MODEL\n",
    "\n",
    "#Linear Regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linear_reg = LinearRegression() #The actual LinearRegression\n",
    "#Cross validation says how well it fits (its kind of like the R^2)\n",
    "scores = cross_val_score(linear_reg, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10) \n",
    "#cv means split it into 90% of data & tests on the 10% of data, & does it 10 times, 1 time for each of the 10%'s of the data. So all the data gets tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative MSE:\n",
      " [-66.85353755 -67.73789277 -67.38375765 -67.94718194 -67.15123786\n",
      " -67.15578224 -67.28593613 -67.50570805 -66.44669993 -67.10832129]\n"
     ]
    }
   ],
   "source": [
    "print(\"Negative MSE:\\n\", scores)\n",
    "\n",
    "#INTRPRET DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE:\n",
      " [8.17640126 8.23030332 8.20876103 8.24300806 8.19458589 8.19486316\n",
      " 8.20280051 8.21618574 8.15148452 8.19196688]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "linear_rmse_scores = np.sqrt(-scores)\n",
    "print(\"\\nRMSE:\\n\", linear_rmse_scores)\n",
    "#Says we are off on averge about $8.2 (plus or minus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Averange Cross-Validation RMSE: 8.201036036366057\n"
     ]
    }
   ],
   "source": [
    "average_cross_validation_Linear_RMSE = linear_rmse_scores.mean();\n",
    "print(\"\\nAverange Cross-Validation RMSE:\", average_cross_validation_Linear_RMSE)\n",
    "\n",
    "#Here is the avg. of about how off we are from the target/Y \n",
    "#So on avg we are off by $8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target Range: ( 2.5 ,  97.5 ) ==>  95.0\n",
      "\n",
      "RMSE relative to range: 8.63%\n"
     ]
    }
   ],
   "source": [
    "target_range = y_train.max()-y_train.min();\n",
    "print(\"\\nTarget Range: (\", y_train.min(), \", \", y_train.max(), \") ==> \", target_range)\n",
    "print(\"\\nRMSE relative to range: {0:0.2%}\".format(average_cross_validation_Linear_RMSE/target_range))\n",
    "#So, if the max is $97.5 and the min is $2.5, and we are off by 8.63%. So, not sucha big deal in big trasnactions. But could be BAD in small ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ok, so now lets try anotherr model & see how we do.\n",
    "\n",
    "#Copy & Paste Above Linear Regression, just replace one line\n",
    "\n",
    "#2nd Degree Polynomial:\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#Poly..Features: Squares and multiplies to make new features/columns/X-variables\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "\n",
    "#Runs Regressions\n",
    "linear_reg = LinearRegression()\n",
    "ridge_reg = Ridge(alpha=0.1, solver=\"cholesky\", max_iter=1000)\n",
    "lasso_reg = Lasso(alpha=0.1, max_iter=1000)\n",
    "elastic_net_reg = ElasticNet(alpha=0.1, l1_ratio=0.5, max_iter=1000)\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "forest_reg = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes time! (Like 15 minutes plus)\n",
    "\n",
    "#Disregard any warnings. IT IS STILL RUNNING!!!!!!\n",
    "\n",
    "print(\"training the linear model\")\n",
    "linear_scores = cross_val_score(linear_reg, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "print(\"done training the linear model -> starting the poly model\")\n",
    "poly_scores = cross_val_score(linear_reg, X_train_poly, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "print(\"done training the poly model -> starting ridge model\")\n",
    "ridge_scores = cross_val_score(linear_reg, X_train_poly, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "print(\"done training the ridge model -> starting lasso model\")\n",
    "lasso_scores = cross_val_score(lasso_reg, X_train_poly, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "print(\"done training the lasso model -> startiong elastic net model\")\n",
    "elastic_net_scores = cross_val_score(elastic_net_reg, X_train_poly, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "print(\"done training the elastic net model -> starting decission tree model\")\n",
    "tree_scores = cross_val_score(tree_reg, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "print(\"done training the decission tree model -> starting random forest model\")\n",
    "forest_scores = cross_val_score(forest_reg, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "print(\"done training the random forest tree model\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lasso_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-067a57f372a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpoly_average_RMSE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpoly_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtarget_range\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mridge_average_RMSE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mridge_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtarget_range\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mlasso_average_RMSE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlasso_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtarget_range\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0melastic_net_average_RMSE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0melastic_net_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtarget_range\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtree_average_RMSE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtree_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtarget_range\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lasso_scores' is not defined"
     ]
    }
   ],
   "source": [
    "#Calculations for graph below\n",
    "target_range = y_train.max()-y_train.min();\n",
    "linear_average_RMSE = np.sqrt(-linear_scores).mean()/target_range;\n",
    "poly_average_RMSE = np.sqrt(-poly_scores).mean()/target_range;\n",
    "ridge_average_RMSE = np.sqrt(-ridge_scores).mean()/target_range;\n",
    "lasso_average_RMSE = np.sqrt(-lasso_scores).mean()/target_range;\n",
    "elastic_net_average_RMSE = np.sqrt(-elastic_net_scores).mean()/target_range;\n",
    "tree_average_RMSE = np.sqrt(-tree_scores).mean()/target_range;\n",
    "forest_average_RMSE = np.sqrt(-forest_scores).mean()/target_range;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lasso_average_RMSE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-ef640b470b4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"linear\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Poly\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ridge\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"lasso\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"elastic net\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"decision tree\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"random forest\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0maverage_RMSEs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlinear_average_RMSE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoly_average_RMSE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mridge_average_RMSE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlasso_average_RMSE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melastic_net_average_RMSE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree_average_RMSE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforest_average_RMSE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'{:.2%}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maverage_RMSEs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lasso_average_RMSE' is not defined"
     ]
    }
   ],
   "source": [
    "x = [1, 2, 3, 4, 5, 6, 7]\n",
    "model_names = [\"linear\", \"Poly\", \"ridge\", \"lasso\", \"elastic net\", \"decision tree\", \"random forest\"]\n",
    "average_RMSEs = np.array([linear_average_RMSE, poly_average_RMSE, ridge_average_RMSE, lasso_average_RMSE, elastic_net_average_RMSE, tree_average_RMSE, forest_average_RMSE])\n",
    "print(['{:.2%}'.format(item) for item in average_RMSEs])\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(x, average_RMSEs)\n",
    "plt.xticks(x, model_names)\n",
    "plt.ylim(ymax=.1) #Max is .1 (= 10% error)\n",
    "plt.show()\n",
    "\n",
    "#decision tree & random forrest only are off 2.44% & 1.93% of the time. They are the best so far\n",
    "#So, they are by about $2\n",
    "#So, customers (cab drivers) I would tell them they would make -$2 on AVERAGE. FIND CASES WHEN ITS WORSE THAN THAT AND COMPENSATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now tune the best models.\n",
    "#Find out how to tune models...hyerparamters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [\n",
    "{'bootstrap': [False], 'max_features': [2, 4, 6], 'n_estimators': [3, 10]},\n",
    "{'bootstrap': [True, False], 'max_features': [2, 6], 'n_estimators': [3, 10]},\n",
    "]\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=10,scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert stuff from above into hyperparameters\n",
    "\n",
    "#Taking best reg & imporving with hyperparamters\n",
    "new_forest_reg = RandomForestRegressor(bootstrap=True, max_features=6, n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features=6, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_forest_reg.fit(X_train, y_train) #Pass in x,y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_model']"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save to file\n",
    "joblib.dump(new_forest_reg, \"saved_model\") #Saves file from new_forest_reg, saves as \"saved_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = joblib.load(\"saved_model\") #loads file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "                      max_features=6, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                      n_jobs=None, oob_score=False, random_state=None,\n",
      "                      verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System:\n",
      "    python: 3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]\n",
      "executable: C:\\Users\\harri\\Anaconda3\\python.exe\n",
      "   machine: Windows-10-10.0.19041-SP0\n",
      "\n",
      "Python deps:\n",
      "       pip: 19.2.3\n",
      "setuptools: 41.4.0\n",
      "   sklearn: 0.21.3\n",
      "     numpy: 1.16.5\n",
      "     scipy: 1.3.1\n",
      "    Cython: 0.29.13\n",
      "    pandas: 0.25.1\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.show_versions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
